<p align="center">

  <h1 align="center">VisiMark: Characterizing and Augmenting Landmarks for People with Low Vision in Augmented Reality to Support Indoor Navigation</h1>
  <p align="center">
    Ruijia Chen<sup>1</sup>, 
    Junru Jiang<sup>1</sup>,
    Pragati Maheshwary<sup>2</sup>, <br>
    Brianna R. Cochran<sup>1</sup>,
    Yuhang Zhao<sup>1</sup>
    <br><br>
    <sup>1</sup>University of Wisconsin-Madison,
    <sup>2</sup>Carnegie Mellon University
    <br>
  </p>
  <h2 align="center">CHI 2025</h2>
  <h3 align="center"><a href="https://github.com/MadisonAbilityLab/VisiMark">Study Materials</a> | <a href="https://dl.acm.org/doi/10.1145/3706598.3713847">Paper </a> </h3>
  <div align="center"></div>
<br>

<p align="center">
  <a href="">
    <img src="https://dl.acm.org/doi/10.1145/3706598.3713847#fig1" alt="Logo" width="100%">
  </a>
</p>
<p align="left">
<strong>VisiMark</strong> is an AR interface that supports landmark perception for <a href="https://www.nei.nih.gov/learn-about-eye-health/eye-conditions-and-diseases/low-vision">people with low vision</a> by providing both overviews of space structures and in-situ landmark augmentations. In this repo, we present our <a href="https://github.com/MadisonAbilityLab/VisiMark/blob/main/Study%20Protocol.pdf">study protocol</a>, <a href="https://github.com/MadisonAbilityLab/VisiMark/blob/main/Scripts%20for%20Summative%20Study.pdf">study scripts for the evaluation</a>, <a href="https://github.com/MadisonAbilityLab/VisiMark/blob/main/Consent%20Form.pdf">consent form</a> for participants, and our qualitative analysis results - <a href="https://github.com/MadisonAbilityLab/VisiMark/blob/main/Themes%20and%20Codebook.pdf">our codebook with themes</a>.
</p>

<br>

## Citation
```bibtex
@inproceedings{chen2025visimark,
  title={VisiMark: Characterizing and Augmenting Landmarks for People with Low Vision in Augmented Reality to Support Indoor Navigation},
  author={Chen, Ruijia and Jiang, Junru and Maheshwary, Pragati and Cochran, Brianna R and Zhao, Yuhang},
  booktitle={Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
  pages={1--20},
  year={2025},
  abstract = {Landmarks are critical in navigation, supporting self-orientation and mental model development. Similar to sighted people, people with low vision (PLV) frequently look for landmarks via visual cues but face difficulties identifying some important landmarks due to vision loss. We first conducted a formative study with six PLV to characterize their challenges and strategies in landmark selection, identifying their unique landmark categories (e.g., area silhouettes, accessibility-related objects) and preferred landmark augmentations. We then designed VisiMark, an AR interface that supports landmark perception for PLV by providing both overviews of space structures and in-situ landmark augmentations. We evaluated VisiMark with 16 PLV and found that VisiMark enabled PLV to perceive landmarks they preferred but could not easily perceive before, and changed PLVâ€™s landmark selection from only visually-salient objects to cognitive landmarks that are more important and meaningful. We further derive design considerations for AR-based landmark augmentation systems for PLV.},
}
```
